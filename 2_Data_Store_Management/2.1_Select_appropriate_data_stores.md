[<- 1.3 Orchestrate data pipelines](../1_Data_Ingestion_and_Transformation/1.3_Orchestrate_data_pipelines.md) | [Table of Contents](../../README.md) | [2.2 Implement data storage solutions ->](./2.2_Implement_data_storage_solutions.md)
---
# Domain 2: Data Store Management
## Task 2.1: Select appropriate data stores

Selecting the right data store is crucial for building efficient, scalable, and cost-effective data solutions on AWS. The choice depends on various factors related to the data itself, how it's accessed, and the application's requirements.

### Factors Influencing Data Store Selection

1.  **Data Structure:**
    *   **Structured:** Data with a predefined schema, typically tabular (rows and columns). Examples: Relational databases (customer records, transactions).
        *   *AWS Services:* RDS, Aurora, Redshift.
    *   **Semi-structured:** Data that doesn't fit a rigid schema but has some organizational properties (e.g., tags, key-value pairs). Examples: JSON, XML, logs.
        *   *AWS Services:* DynamoDB, DocumentDB, OpenSearch Service, S3 (for storing files).
    *   **Unstructured:** Data without a predefined schema or organization. Examples: Images, videos, audio files, free-form text documents.
        *   *AWS Services:* S3, S3 Glacier.

2.  **Access Patterns:**
    *   How frequently is data read vs. written? (Read-heavy, write-heavy, balanced)
    *   What are the typical query types? (Simple lookups by key, complex analytical queries, graph traversals, time-series analysis)
    *   Are point-in-time lookups or range queries needed?

3.  **Query Requirements:**
    *   **Latency:** How fast do queries need to return? (Millisecond latency for transactional systems vs. minutes/hours for batch analytics).
    *   **Throughput:** How many queries per second need to be supported?
    *   **Complexity:** Simple key lookups, complex joins, aggregations, full-text search, graph traversals.

4.  **Performance & Scalability:**
    *   **Read/Write Performance:** Required IOPS, throughput.
    *   **Scalability:** Ability to handle growing data volumes and user load. Does it need to scale reads, writes, or both? Does it support automatic scaling?
    *   **Concurrency:** How many users/applications will access the data store simultaneously?

5.  **Cost:**
    *   Storage costs (per GB).
    *   Compute costs (instance types, provisioned capacity).
    *   Data transfer costs.
    *   Request costs (e.g., S3 GET/PUT, DynamoDB RCU/WCU).
    *   Operational overhead (managed vs. self-managed).

6.  **Durability & Availability:**
    *   **Durability:** Protection against data loss (e.g., S3's 99.999999999% durability).
    *   **Availability:** Percentage of time the service is operational (e.g., Multi-AZ deployments for RDS/Aurora).
    *   Backup and recovery requirements (RPO/RTO).

7.  **Consistency Models:**
    *   **Strong Consistency:** Reads always return the most recently written data. Often comes with higher latency or lower availability. (e.g., RDS, Aurora default).
    *   **Eventual Consistency:** Reads might return stale data shortly after a write, but will eventually return the latest version. Often offers higher availability and lower latency. (e.g., DynamoDB default, S3).
    *   **Read-after-Write Consistency:** A specific type where a user is guaranteed to read their own writes immediately.

### Key AWS Data Stores

| Service                 | Type                     | Data Structure        | Primary Use Cases                                                                 | Key Characteristics                                                                                                |
| :---------------------- | :----------------------- | :-------------------- | :-------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |
| **Amazon S3**           | Object Storage           | Unstructured          | Data lakes, backups, static website hosting, big data analytics input/output      | Highly durable (11 9s), scalable, cost-effective, various storage classes, event notifications, versioning.        |
| **S3 Glacier**          | Archive Storage          | Unstructured          | Long-term data archival, compliance, low-cost storage for infrequently accessed data | Extremely low cost, various retrieval options (minutes to hours), Vault Lock for compliance.                      |
| **Amazon Redshift**     | Data Warehouse           | Structured            | Business intelligence (BI), analytics, complex SQL queries on large datasets      | Columnar storage, massively parallel processing (MPP), SQL interface, integrates with data lakes (Redshift Spectrum). |
| **Amazon DynamoDB**     | NoSQL Key-Value/Document | Semi-structured (JSON)| High-traffic web apps, mobile apps, gaming, IoT, low-latency key-based lookups    | Serverless, highly scalable, predictable performance (provisioned/on-demand capacity), eventual/strong consistency. |
| **Amazon RDS**          | Relational Database      | Structured            | Transactional applications (OLTP), web applications, content management systems   | Managed service for MySQL, PostgreSQL, MariaDB, SQL Server, Oracle. Multi-AZ, read replicas, automated backups.   |
| **Amazon Aurora**       | Relational Database      | Structured            | High-performance, high-availability relational database needs                     | MySQL/PostgreSQL compatible, cloud-native, auto-scaling storage, fault-tolerant, faster than standard MySQL/Postgres. |
| **Amazon Neptune**      | Graph Database           | Graph (Nodes/Edges)   | Social networking, recommendation engines, fraud detection, knowledge graphs      | Fully managed, supports Gremlin and SPARQL query languages, optimized for complex relationship queries.           |
| **Amazon Timestream**   | Time-Series Database     | Time-series           | IoT sensor data, application monitoring, operational metrics, time-stamped events | Serverless, optimized for time-ordered data, built-in analytics functions (interpolation, smoothing).            |
| **Amazon OpenSearch**   | Search & Analytics       | Semi-structured (JSON)| Log analytics, real-time application monitoring, full-text search, clickstream analysis | Managed Elasticsearch/OpenSearch, powerful search DSL, Kibana/OpenSearch Dashboards for visualization.           |
| **MemoryDB for Redis**  | In-Memory Database       | Key-Value             | Microservices needing durable, low-latency data access, session management, leaderboards | Redis-compatible, durable (multi-AZ transaction logs), ultra-fast performance, designed for primary database use. |
| **Amazon DocumentDB**   | Document Database        | Semi-structured (JSON)| Content management, catalogs, user profiles, applications needing flexible schemas  | MongoDB-compatible, managed, scalable, highly available, focuses on JSON-like documents.                        |

### Selection Scenarios

*   **Need to store large binary files (images, videos) durably and cost-effectively?** -> **S3**
*   **Need long-term, cheap archival for compliance?** -> **S3 Glacier**
*   **Need to run complex analytical SQL queries on terabytes of structured data?** -> **Redshift**
*   **Need millisecond latency for simple key lookups on a massive scale?** -> **DynamoDB**
*   **Need a traditional relational database for an OLTP application?** -> **RDS** or **Aurora** (for higher performance/availability)
*   **Need to analyze relationships and connections in data?** -> **Neptune**
*   **Need to store and query time-stamped data efficiently?** -> **Timestream**
*   **Need powerful full-text search and log analytics?** -> **OpenSearch Service**
*   **Need an ultra-fast, durable in-memory store?** -> **MemoryDB for Redis**
*   **Need a managed MongoDB-compatible database?** -> **DocumentDB**

Understanding these factors and the strengths of each AWS data store allows data engineers to make informed decisions that align with application requirements and business goals.